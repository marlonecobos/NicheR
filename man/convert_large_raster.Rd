% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/convert_large_raster.R
\name{convert_large_raster}
\alias{convert_large_raster}
\title{Convert a Large Raster Stack to a Disk-Backed Table (Chunked) + RData}
\usage{
convert_large_raster(
  raster_stack,
  out_filename = "raster_db",
  chunk_height = 500,
  keep_sql = FALSE,
  verbose = TRUE
)
}
\arguments{
\item{raster_stack}{A multi-layer raster object. Supports
\code{terra::SpatRaster} or \code{raster::Raster*}. Must have valid
georeferencing so that \code{xmin}, \code{xmax}, \code{ymin}, and
row-to-\eqn{y} conversions are defined.}

\item{out_filename}{Character base name (without extension) for outputs.
Files \code{<out_filename>.sqlite} and \code{<out_filename>.RData} are
written into the current working directory.}

\item{chunk_height}{Positive integer. Number of raster rows per chunk to
process and append to the SQL table. Smaller values reduce memory usage
but increase the number of DB writes.}

\item{keep_sql}{Logical. If \code{TRUE}, the temporary SQLite file is kept
on disk after the `.RData` is saved. If \code{FALSE} (default), it is
deleted at the end.}

\item{verbose}{Logical. If \code{TRUE}, prints progress and file paths.}
}
\value{
(Invisibly) returns a \code{data.frame} with columns \code{x}, \code{y},
  and one column per raster layer (matching \code{names(raster_stack)}).
  Also writes \code{<out_filename>.RData} containing an object named
  \code{env_df}. If \code{keep_sql = TRUE}, also leaves
  \code{<out_filename>.sqlite} on disk with table \code{raster_table}.
}
\description{
Converts a (potentially very large) raster stack into a SQLite table by
iterating over row-chunks, appending each chunk as a data frame of cell
values with `x`/`y` coordinates. After processing, the full table is read
back into R and saved as an `.RData` file. Optionally keeps the SQLite file
for later DB-backed workflows.
}
\details{
The function:
\enumerate{
\item Creates (or overwrites) a SQLite DB and an empty table \code{raster_table}
      with schema \code{x, y, layer1, ..., layerK}.
\item Iterates over raster rows in blocks of \code{chunk_height}, crops each
      block by geographic extent, converts it to a data frame with
      \code{xy = TRUE}, and appends it to \code{raster_table}.
\item Reads the full table back into R as \code{env_df}, disconnects from
      the DB, saves \code{env_df} to \code{<out_filename>.RData}, and
      optionally removes the SQLite file.
}

This design avoids loading the entire raster into memory and is suitable for
stacks with many layers or very large dimensions.
}
\section{Notes}{

\itemize{
\item Output files are written in \code{getwd()} unless absolute paths are provided
      in \code{out_filename}.
\item For reproducibility and resilience, consider wrapping the DB connection in
      \code{on.exit(DBI::dbDisconnect(conn), add = TRUE)}.
}
}

\seealso{
\code{\link[DBI]{dbConnect}}, \code{\link[RSQLite]{SQLite}},
  \code{\link[terra]{as.data.frame}}, \code{\link[terra]{crop}},
  \code{\link[terra]{ext}}
}
